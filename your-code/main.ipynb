{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping Lab\n",
    "\n",
    "You will find in this notebook some scrapy exercises to practise your scraping skills.\n",
    "\n",
    "**Tips:**\n",
    "\n",
    "- Check the response status code for each request to ensure you have obtained the intended contennt.\n",
    "- Print the response text in each request to understand the kind of info you are getting and its format.\n",
    "- Check for patterns in the response text to extract the data/info requested in each question.\n",
    "- Visit each url and take a look at its source through Chrome DevTools. You'll need to identify the html tags, special class names etc. used for the html content you are expected to extract."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Requests library](http://docs.python-requests.org/en/master/#the-user-guide) documentation \n",
    "- [Beautiful Soup Doc](https://www.crummy.com/software/BeautifulSoup/bs4/doc/)\n",
    "- [Urllib](https://docs.python.org/3/library/urllib.html#module-urllib)\n",
    "- [re lib](https://docs.python.org/3/library/re.html)\n",
    "- [lxml lib](https://lxml.de/)\n",
    "- [Scrapy](https://scrapy.org/)\n",
    "- [List of HTTP status codes](https://en.wikipedia.org/wiki/List_of_HTTP_status_codes)\n",
    "- [HTML basics](http://www.simplehtmlguide.com/cheatsheet.php)\n",
    "- [CSS basics](https://www.cssbasics.com/#page_start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Below are the libraries and modules you may need. `requests`,  `BeautifulSoup` and `pandas` are imported for you. If you prefer to use additional libraries feel free to uncomment them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "from lxml import html\n",
    "from lxml.html import fromstring\n",
    "import urllib.request\n",
    "from urllib.request import urlopen\n",
    "import random\n",
    "import re\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download, parse (using BeautifulSoup), and print the content from the Trending Developers page from GitHub:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://github.com/trending/developers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\" data-a11y-animated-images=\"system\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">\\n  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>\\n  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">\\n\\n\\n\\n  <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/light-5178aee0ee76.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/dark-217d4f9c8e70.css\" /><link data-color-theme=\"dark_dimmed\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.gith'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = req.get(url).content\n",
    "\n",
    "html[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=bs(html,'html.parser')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the names of the trending developers retrieved in the previous step.\n",
    "\n",
    "Your output should be a Python list of developer names. Each name should not contain any html tag.\n",
    "\n",
    "**Instructions:**\n",
    "\n",
    "1. Find out the html tag and class names used for the developer names. You can achieve this using Chrome DevTools.\n",
    "\n",
    "1. Use BeautifulSoup to extract all the html elements that contain the developer names.\n",
    "\n",
    "1. Use string manipulation techniques to replace whitespaces and linebreaks (i.e. `\\n`) in the *text* of each html element. Use a list to store the clean names.\n",
    "\n",
    "1. Print the list of names.\n",
    "\n",
    "Your output should look like below:\n",
    "\n",
    "```\n",
    "['trimstray (@trimstray)',\n",
    " 'joewalnes (JoeWalnes)',\n",
    " 'charlax (Charles-AxelDein)',\n",
    " 'ForrestKnight (ForrestKnight)',\n",
    " 'revery-ui (revery-ui)',\n",
    " 'alibaba (Alibaba)',\n",
    " 'Microsoft (Microsoft)',\n",
    " 'github (GitHub)',\n",
    " 'facebook (Facebook)',\n",
    " 'boazsegev (Bo)',\n",
    " 'google (Google)',\n",
    " 'cloudfetch',\n",
    " 'sindresorhus (SindreSorhus)',\n",
    " 'tensorflow',\n",
    " 'apache (TheApacheSoftwareFoundation)',\n",
    " 'DevonCrawford (DevonCrawford)',\n",
    " 'ARMmbed (ArmMbed)',\n",
    " 'vuejs (vuejs)',\n",
    " 'fastai (fast.ai)',\n",
    " 'QiShaoXuan (Qi)',\n",
    " 'joelparkerhenderson (JoelParkerHenderson)',\n",
    " 'torvalds (LinusTorvalds)',\n",
    " 'CyC2018',\n",
    " 'komeiji-satori (神楽坂覚々)',\n",
    " 'script-8']\n",
    " ```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Azure SDK Bot'], ['Azure SDK Bot'], ['Azure SDK Bot']]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows= soup.find('h1', class_= \"h3 lh-condensed\")\n",
    "\n",
    "rows= [rows.text.strip().split('\\n') for row in rows]\n",
    "rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the trending Python repositories in GitHub\n",
    "\n",
    "The steps to solve this problem is similar to the previous one except that you need to find out the repository names instead of developer names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://github.com/trending/python?since=daily'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'\\n\\n<!DOCTYPE html>\\n<html lang=\"en\" data-color-mode=\"auto\" data-light-theme=\"light\" data-dark-theme=\"dark\" data-a11y-animated-images=\"system\">\\n  <head>\\n    <meta charset=\"utf-8\">\\n  <link rel=\"dns-prefetch\" href=\"https://github.githubassets.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://avatars.githubusercontent.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://github-cloud.s3.amazonaws.com\">\\n  <link rel=\"dns-prefetch\" href=\"https://user-images.githubusercontent.com/\">\\n  <link rel=\"preconnect\" href=\"https://github.githubassets.com\" crossorigin>\\n  <link rel=\"preconnect\" href=\"https://avatars.githubusercontent.com\">\\n\\n\\n\\n  <link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/light-5178aee0ee76.css\" /><link crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" href=\"https://github.githubassets.com/assets/dark-217d4f9c8e70.css\" /><link data-color-theme=\"dark_dimmed\" crossorigin=\"anonymous\" media=\"all\" rel=\"stylesheet\" data-href=\"https://github.gith'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = req.get(url).content\n",
    "\n",
    "html[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup=bs(html,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":53356347,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"8727d185f53f762334cfdc2ea5043cd4545e05f0bd0bd486e3e5d85a2f414d17\" data-view-component=\"true\" href=\"/azure-sdk\">\n",
       "             Azure SDK Bot\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":12907710,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"1932509fed3bf5f3d1fadf05a9579b2c47ee49309bd4ae7f56f7c86cd2393ba7\" data-view-component=\"true\" href=\"/RangiLyu\">\n",
       "             RangiLyu\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":5555347,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"f4bc59b840f5b430b6f85b08232fdd5ba707fd6af5391c982be261f27d307985\" data-view-component=\"true\" href=\"/vwxyzjn\">\n",
       "             Costa Huang\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":4660275,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"71515a6198349161f1388602de97ec09f127095bae7bf3100180bb143d589b7d\" data-view-component=\"true\" href=\"/sobolevn\">\n",
       "             Nikita Sobolev\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":21316711,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"0d09de874d32e4afe424cd6f97fba0e3f5fd09bf9e794c6b57ccb6051b2adef3\" data-view-component=\"true\" href=\"/Joshua-Ashton\">\n",
       "             Joshie\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":2345875,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"9d5bfe35efb999379df1e18b173c89d504feefd8b4a0ce201ba6023f6478e2cd\" data-view-component=\"true\" href=\"/bramstroker\">\n",
       "             Bram Gerritsen\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":19784933,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"080c2026ebdaf0f9de69e0339dccc1f852c22044066a9676136f14e880a28d57\" data-view-component=\"true\" href=\"/aminalaee\">\n",
       "             Amin Alaee\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":6942,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"ae4d88ee5e13d3dde068e007ac82a7f833337ff5f2c845dc36a8c6dfc69b5b19\" data-view-component=\"true\" href=\"/twpayne\">\n",
       "             Tom Payne\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":82342,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"a8324adccb393983e3bd3ded846d76e4f0800f7f6e85c16e72dfc20163fbc8fd\" data-view-component=\"true\" href=\"/ripienaar\">\n",
       "             R.I.Pienaar\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":663432,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"8bcd057ac3b55782c952595f7a06533ea299b7c6b37a29faff77eb6f9a3b611a\" data-view-component=\"true\" href=\"/bdraco\">\n",
       "             J. Nick Koston\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":857609,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"855eb4f47c1b7fca09280d72b1498213b965c4ddfeb4d0949140dc5f357b1956\" data-view-component=\"true\" href=\"/adamchainz\">\n",
       "             Adam Johnson\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":3797675,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"f49a70e17460b5acfd59b00cf5eae3ea1eca671f3057d5a7c561e6ece3c641f2\" data-view-component=\"true\" href=\"/stefanprodan\">\n",
       "             Stefan Prodan\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":211411,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"38302e6f68e08f61bdc9607fe4fc9c736ea77ea16d494abf4d53e9dbaf934305\" data-view-component=\"true\" href=\"/gre\">\n",
       "             @greweb\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1609021,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"b9bf33e5808aecd28d7472a53a46a87299e798bd34fbb889c06f48f6523846da\" data-view-component=\"true\" href=\"/dsherret\">\n",
       "             David Sherret\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1596303,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"3b055a8d2b1c0f95948c80ccf9b45002beac4bb81c4df970b22b61329692405b\" data-view-component=\"true\" href=\"/rochdev\">\n",
       "             Roch Devost\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":209371,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"e15f0ade6603a7fcce8cb4a97520bf3de598a3dc9287dd15a688eddf04d676ad\" data-view-component=\"true\" href=\"/asterite\">\n",
       "             Ary Borenszweig\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":4196,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"5b95ca6ca70cbd0ca71222571843a17733b73e0a0526c5d08003db36afc8dfac\" data-view-component=\"true\" href=\"/hadley\">\n",
       "             Hadley Wickham\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":378614,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"c9c7147ad4ebbed57533401b90065b3dab600b449c90d263ba85aeb151f94c28\" data-view-component=\"true\" href=\"/ben-manes\">\n",
       "             Ben Manes\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":452425,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"ff1a1cd864defc304b0aa0e270eed053ff28bc0738784f04063886932281c95f\" data-view-component=\"true\" href=\"/adamdbradley\">\n",
       "             Adam Bradley\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":46275,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"06df8482f7021f7318b2eb0242e258078705d06974fbecac3656f86ef1e5471c\" data-view-component=\"true\" href=\"/munificent\">\n",
       "             Bob Nystrom\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1148717,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"e63714fba102c81161256026f733701b107c533357596fd3a9b8b0ccdb58acba\" data-view-component=\"true\" href=\"/emilk\">\n",
       "             Emil Ernerfeldt\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":78784850,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"33180dcb5da019d82d3bfd9c1aa651de7fe1a3b203874ffb0c100020238e9f2e\" data-view-component=\"true\" href=\"/Dun-sin\">\n",
       "             Dunsin\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":16662357,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"6297a619216d637ec51d993e88d3985751cbd334c92b75c91948e7f54f52c782\" data-view-component=\"true\" href=\"/jdhao\">\n",
       "             jdhao\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":1948812,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"a854c5a8655a2c025c8355c8d89e153a56a5e7581ef8e667a9dc3802cce8bc89\" data-view-component=\"true\" href=\"/DonJayamanne\">\n",
       "             Don Jayamanne\n",
       " </a> </h1>,\n",
       " <h1 class=\"h3 lh-condensed\">\n",
       " <a data-hydro-click='{\"event_type\":\"explore.click\",\"payload\":{\"click_context\":\"TRENDING_DEVELOPERS_PAGE\",\"click_target\":\"OWNER\",\"click_visual_representation\":\"TRENDING_DEVELOPER\",\"actor_id\":null,\"record_id\":7783288,\"originating_url\":\"https://github.com/trending/developers\",\"user_id\":null}}' data-hydro-click-hmac=\"f846f492d43e9ec391c3192f33abad6ebefd64ed83e8b8a7ccd124bf017d187e\" data-view-component=\"true\" href=\"/mtlynch\">\n",
       "             Michael Lynch\n",
       " </a> </h1>]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows= soup.find_all('h1', class_= \"h3 lh-condensed\")\n",
    "\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Azure SDK Bot'],\n",
       " ['RangiLyu'],\n",
       " ['Costa Huang'],\n",
       " ['Nikita Sobolev'],\n",
       " ['Joshie'],\n",
       " ['Bram Gerritsen'],\n",
       " ['Amin Alaee'],\n",
       " ['Tom Payne'],\n",
       " ['R.I.Pienaar'],\n",
       " ['J. Nick Koston'],\n",
       " ['Adam Johnson'],\n",
       " ['Stefan Prodan'],\n",
       " ['@greweb'],\n",
       " ['David Sherret'],\n",
       " ['Roch Devost'],\n",
       " ['Ary Borenszweig'],\n",
       " ['Hadley Wickham'],\n",
       " ['Ben Manes'],\n",
       " ['Adam Bradley'],\n",
       " ['Bob Nystrom'],\n",
       " ['Emil Ernerfeldt'],\n",
       " ['Dunsin'],\n",
       " ['jdhao'],\n",
       " ['Don Jayamanne'],\n",
       " ['Michael Lynch']]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows= soup.find_all('h1', class_= \"h3 lh-condensed\")\n",
    "\n",
    "rows= [rows.text.strip().split('\\n') for rows in rows]\n",
    "rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#repos de Github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['azure-docs-sdk-java'],\n",
       " ['nanodet'],\n",
       " ['cleanrl'],\n",
       " ['awesome-cryptography'],\n",
       " ['VPhysics-Jolt'],\n",
       " ['homeassistant-powercalc'],\n",
       " ['sqladmin'],\n",
       " ['chezmoi'],\n",
       " ['free-for-dev'],\n",
       " ['django-cors-headers'],\n",
       " ['podinfo'],\n",
       " ['react-native-view-shot'],\n",
       " ['ts-morph'],\n",
       " ['r4ds'],\n",
       " ['caffeine'],\n",
       " ['craftinginterpreters'],\n",
       " ['egui'],\n",
       " ['trick-generator'],\n",
       " ['nvim-config'],\n",
       " ['typescript-notebook'],\n",
       " ['picoshare']]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "repos= soup.find_all('h1', class_= \"h4 lh-condensed\")\n",
    "\n",
    "repos= [repos.text.strip().split('\\n') for repos in repos]\n",
    "repos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display all the image links from Walt Disney wikipedia page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_2 = 'https://en.wikipedia.org/wiki/Walt_Disney'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<!DOCTYPE html>\\n<html class=\"client-nojs\" lang=\"en\" dir=\"ltr\">\\n<head>\\n<meta charset=\"UTF-8\"/>\\n<title>Walt Disney - Wikipedia</title>\\n<script>document.documentElement.className=\"client-js\";RLCONF={\"wgBreakFrames\":false,\"wgSeparatorTransformTable\":[\"\",\"\"],\"wgDigitTransformTable\":[\"\",\"\"],\"wgDefaultDateFormat\":\"dmy\",\"wgMonthNames\":[\"\",\"January\",\"February\",\"March\",\"April\",\"May\",\"June\",\"July\",\"August\",\"September\",\"October\",\"November\",\"December\"],\"wgRequestId\":\"c4234a2d-425a-48d2-b7d2-0946d7a00696\",\"wgCSPNonce\":false,\"wgCanonicalNamespace\":\"\",\"wgCanonicalSpecialPageName\":false,\"wgNamespaceNumber\":0,\"wgPageName\":\"Walt_Disney\",\"wgTitle\":\"Walt Disney\",\"wgCurRevisionId\":1107094487,\"wgRevisionId\":1107094487,\"wgArticleId\":32917,\"wgIsArticle\":true,\"wgIsRedirect\":false,\"wgAction\":\"view\",\"wgUserName\":null,\"wgUserGroups\":[\"*\"],\"wgCategories\":[\"Pages containing links to subscription-only content\",\"Articles with short description\",\"Short description matches Wikidata\",\"Featured articles\",\"Wikipedia indefinitely move-protected pages\",\"Wikipedia extended-confirmed-protected pages\",\"Use mdy dates from November 2020\",\\n\"Use American English from May 2016\",\"All Wikipedia articles written in American English\",\"Biography with signature\",\"Articles with hCards\",\"Articles containing German-language text\",\"Articles containing French-language text\",\"Articles containing Spanish-language text\",\"TCMDb name template using non-numeric ID from Wikidata\",\"Articles using Template:The Interviews people\",\"Pages using Sister project links with hidden wikidata\",\"Articles with ISNI identifiers\",\"Articles with VIAF identifiers\",\"Articles with WORLDCATID identifiers\",\"Articles with BIBSYS identifiers\",\"Articles with BNE identifiers\",\"Articles with BNF identifiers\",\"Articles with CANTICN identifiers\",\"Articles with GND identifiers\",\"Articles with ICCU identifiers\",\"Articles with J9U identifiers\",\"Articles with LCCN identifiers\",\"Articles with LNB identifiers\",\"Articles with NDL identifiers\",\"Articles with NKC identifiers\",\"Articles with NLA identifiers\",\"Articles with NLG identifiers\",\"Articles with NLK identifiers\",\\n\"Articles with NLR identifiers\",\"Articles with NSK identifiers\",\"Articles with NTA identifiers\",\"Articles with PLWABN identifiers\",\"Articles with SELIBR identifiers\",\"Articles with AAG identifiers\",\"Articles with PIC identifiers\",\"Articles with RKDartists identifiers\",\"Articles with ULAN identifiers\",\"Articles with DTBIO identifiers\",\"Articles with CINII identifiers\",\"Articles with FAST identifiers\",\"Articles with MusicBrainz identifiers\",\"Articles with NARA identifiers\",\"Articles with RISM identifiers\",\"Articles with RERO identifiers\",\"Articles with SNAC-ID identifiers\",\"Articles with SUDOC identifiers\",\"Articles with Trove identifiers\",\"AC with 36 elements\",\"Articles with multiple identifiers\",\"Articles containing video clips\",\"Walt Disney\",\"1901 births\",\"1966 deaths\",\"20th-century American artists\",\"20th-century American businesspeople\",\"20th-century American male actors\",\"20th-century American male writers\",\"20th-century American screenwriters\",\"20th-century American writers\",\\n\"Academy Honorary Award recipients\",\"American Red Cross personnel\",\"American animated film producers\",\"American anti-communists\",\"American anti-fascists\",\"American cartoonists\",\"American company founders\",\"American film production company founders\",\"American film studio executives\",\"American male screenwriters\",\"American male voice actors\",\"American mass media owners\",\"American people of Canadian descent\",\"American people of English descent\",\"American people of German descent\",\"American people of Irish descent\",\"American television hosts\",\"Amusement park owners\",\"Animators from Illinois\",\"Animators from Missouri\",\"Artists from Chicago\",\"Burials at Forest Lawn Memorial Park (Glendale)\",\"Cecil B. DeMille Award Golden Globe winners\",\"Chairmen of The Walt Disney Company\",\"Chevaliers of the L\\xc3\\xa9gion d\\'honneur\",\"Congressional Gold Medal recipients\",\"C\\xc3\\xa9sar Honorary Award recipients\",\"Deaths from cancer in California\",\"Deaths from lung cancer\",\"Disney executives\",\"Disney family\",\\n\"Federal Bureau of Investigation informants\",\"Film directors from Missouri\",\"Film producers from Missouri\",\"History of animation\",\"Kansas City Art Institute alumni\",\"Laugh-O-Gram Studio people\",\"Male actors from Missouri\",\"Officers Crosses of the Order of Merit of the Federal Republic of Germany\",\"People from Holmby Hills, Los Angeles\",\"People from Marceline, Missouri\",\"Philanthropists from Illinois\",\"Presidential Medal of Freedom recipients\",\"Primetime Emmy Award winners\",\"Producers who won the Best Animated Short Academy Award\",\"Producers who won the Best Documentary Short Subject Academy Award\",\"Producers who won the Live Action Short Film Academy Award\",\"Recipients of the Irving G. Thalberg Memorial Award\",\"School of the Art Institute of Chicago alumni\",\"Screenwriters from Illinois\",\"Spokespersons\",\"Writers from Chicago\",\"Writers from Missouri\"],\"wgPageContentLanguage\":\"en\",\"wgPageContentModel\"'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = req.get(url_2).content\n",
    "\n",
    "html[0:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= bs(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "disney= soup.find_all('a', class_= \"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/wiki/File:Walt_Disney_1946.JPG'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disney= soup.find_all('a', class_= \"image\")\n",
    "disney[0]['href']\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "photos = []\n",
    "\n",
    "for f in range(len(disney)):\n",
    "    photos.append(disney[f]['href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/wiki/File:Walt_Disney_1946.JPG',\n",
       " '/wiki/File:Walt_Disney_1942_signature.svg',\n",
       " '/wiki/File:Walt_Disney_Birthplace_Exterior_Hermosa_Chicago_Illinois.jpg',\n",
       " '/wiki/File:Walt_Disney_envelope_ca._1921.jpg',\n",
       " '/wiki/File:Trolley_Troubles_poster.jpg',\n",
       " '/wiki/File:Steamboat-willie.jpg',\n",
       " '/wiki/File:Walt_Disney_1935.jpg',\n",
       " '/wiki/File:Walt_Disney_Snow_white_1937_trailer_screenshot_(13).jpg',\n",
       " '/wiki/File:Disney_drawing_goofy.jpg',\n",
       " '/wiki/File:WaltDisneyplansDisneylandDec1954.jpg',\n",
       " '/wiki/File:Walt_disney_portrait_right.jpg',\n",
       " '/wiki/File:DisneySchiphol1951.jpg',\n",
       " '/wiki/File:Walt_Disney_Grave.JPG',\n",
       " '/wiki/File:Roy_O._Disney_with_Company_at_Press_Conference.jpg',\n",
       " '/wiki/File:Disney_Oscar_1953_(cropped).jpg',\n",
       " '/wiki/File:Disney1968.jpg',\n",
       " '/wiki/File:Disneyland_Resort_logo.svg',\n",
       " '/wiki/File:Animation_disc.svg',\n",
       " '/wiki/File:Magic_Kingdom_castle.jpg',\n",
       " '/wiki/File:Blank_television_set.svg']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "photos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve an arbitary Wikipedia page of \"Python\" and create a list of links on that page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_3 ='https://en.wikipedia.org/wiki/Python' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "html = req.get(url_3).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup= bs(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "python= soup.find_all('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "python_links= []\n",
    "\n",
    "for line in python:\n",
    "    if 'https' in str(line.get('href')):\n",
    "        python_links.append(line.get('href'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Titles that have changed in the United States Code since its last release point "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_3 = 'http://uscode.house.gov/download/download.shtml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "b'<?xml version=\\'1.0\\' encoding=\\'UTF-8\\' ?>\\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0 Transitional//EN\" \"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd\">\\n<html xmlns=\"http://www.w3.org/1999/xhtml\"><head>\\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\" />\\n        <meta http-equiv=\"X-UA-Compatible\" content=\"IE=8\" />\\n        <meta http-equiv=\"pragma\" content=\"no-cache\" /><!-- HTTP 1.0 -->\\n        <meta http-equiv=\"cache-control\" content=\"no-cache,must-revalidate\" /><!-- HTTP 1.1 -->\\n        <meta http-equiv=\"expires\" content=\"0\" />\\n        <link rel=\"shortcut icon\" href=\"/javax.faces.resource/favicon.ico.xhtml?ln=images\" /><link type=\"text/css\" rel=\"stylesheet\" href=\"/javax.faces.resource/cssLayout.css.xhtml?ln=css\" /><script type=\"text/javascript\" src=\"/javax.faces.resource/jsf.js.xhtml?ln=javax.faces\"></script><link type=\"text/css\" rel=\"stylesheet\" href=\"/javax.faces.resource/static.css.xhtml?ln=css\" /></head><body style=\"display:none;\"><script type=\"t'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html = req.get(url_3).content\n",
    "\n",
    "html[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_3= bs(html,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "usa= soup_3.find_all(class_= 'usctitlechanged')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Title 2 - The Congress'],\n",
       " ['Title 5 - Government Organization and Employees ٭'],\n",
       " ['Title 10 - Armed Forces ٭'],\n",
       " ['Title 28 - Judiciary and Judicial Procedure ٭'],\n",
       " [\"Title 38 - Veterans' Benefits ٭\"]]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "usa= soup_3.find_all(class_= \"usctitlechanged\")\n",
    "\n",
    "usa= [usa.text.strip().split('\\n') for usa in usa]\n",
    "usa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A Python list with the top ten FBI's Most Wanted names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_4 = 'https://www.fbi.gov/wanted/topten'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = req.get(url_4).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_4= bs(html,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ALEXIS FLORES'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi= soup_4.find_all('h3', class_= 'title')\n",
    "fbi[0].text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALEXIS FLORES',\n",
       " 'JOSE RODOLFO VILLARREAL-HERNANDEZ',\n",
       " 'YULAN ADONAY ARCHAGA CARIAS',\n",
       " 'BHADRESHKUMAR CHETANBHAI PATEL',\n",
       " 'OMAR ALEXANDER CARDENAS',\n",
       " 'ALEJANDRO ROSALES CASTILLO',\n",
       " 'RUJA IGNATOVA',\n",
       " 'JASON DEREK BROWN',\n",
       " 'ARNOLDO JIMENEZ',\n",
       " 'RAFAEL CARO-QUINTERO']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fbi_data = []\n",
    "\n",
    "for i in range(len(fbi)):\n",
    "    fbi_data.append(fbi[i].text.strip())\n",
    "    \n",
    "fbi_data   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  20 latest earthquakes info (date, time, latitude, longitude and region name) by the EMSC as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url = 'https://www.emsc-csem.org/Earthquake/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display the date, days, title, city, country of next 25 hackathon events as a Pandas dataframe table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url ='https://hackevents.co/hackathons'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code #no se puede hacer, link roto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count number of tweets by a given Twitter account."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** for account names not found. \n",
    "<br>***Hint:*** the program should count the number of tweets for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of followers of a given twitter account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will need to include a ***try/except block*** in case account/s name not found. \n",
    "<br>***Hint:*** the program should count the followers for any provided account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List all language names and number of related articles in the order they appear in wikipedia.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_5 = 'https://www.wikipedia.org/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = req.get(url_5).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_5= bs(html,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki= soup_5.find_all('strong')[1:11]\n",
    "lang=[]\n",
    "\n",
    "for l in range(len(wiki)):\n",
    "    lang.append(wiki[l].text.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A list with the different kind of datasets available in data.gov.uk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_6 = 'https://data.gov.uk/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = req.get(url_6).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_6= bs(html,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Business and economy',\n",
       " 'Crime and justice',\n",
       " 'Defence',\n",
       " 'Education',\n",
       " 'Environment',\n",
       " 'Government',\n",
       " 'Government spending',\n",
       " 'Health',\n",
       " 'Mapping',\n",
       " 'Society',\n",
       " 'Towns and cities',\n",
       " 'Transport',\n",
       " 'Digital service performance',\n",
       " 'Government reference data']"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gob= soup_6.find_all('h3')\n",
    "\n",
    "df=[]\n",
    "\n",
    "for i in range(len(gob)):\n",
    "    df.append(gob[i].text.strip())\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top 10 languages by number of native speakers stored in a Pandas Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise\n",
    "url_7 = 'https://en.wikipedia.org/wiki/List_of_languages_by_number_of_native_speakers'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "html = req.get(url_7).content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_7= bs(html,'html.parser')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiki_lang= soup_7.find_all('tr')\n",
    "\n",
    "wiki_lang_rows = [wiki.text.strip().split(\"\\n\") for wiki in wiki_lang]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th></th>\n",
       "      <th>Native Speakers(millions)</th>\n",
       "      <th></th>\n",
       "      <th>Percentageof world pop.(March 2019)[10]</th>\n",
       "      <th></th>\n",
       "      <th>Language family</th>\n",
       "      <th></th>\n",
       "      <th>Branch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td></td>\n",
       "      <td>Mandarin Chinese</td>\n",
       "      <td></td>\n",
       "      <td>929.0</td>\n",
       "      <td></td>\n",
       "      <td>11.922%</td>\n",
       "      <td></td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td></td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>Spanish</td>\n",
       "      <td></td>\n",
       "      <td>474.7</td>\n",
       "      <td></td>\n",
       "      <td>5.994%</td>\n",
       "      <td></td>\n",
       "      <td>Indo-European</td>\n",
       "      <td></td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td></td>\n",
       "      <td>English</td>\n",
       "      <td></td>\n",
       "      <td>372.9</td>\n",
       "      <td></td>\n",
       "      <td>4.922%</td>\n",
       "      <td></td>\n",
       "      <td>Indo-European</td>\n",
       "      <td></td>\n",
       "      <td>Germanic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td></td>\n",
       "      <td>Hindi (Sanskritised Hindustani)[11]</td>\n",
       "      <td></td>\n",
       "      <td>343.9</td>\n",
       "      <td></td>\n",
       "      <td>4.429%</td>\n",
       "      <td></td>\n",
       "      <td>Indo-European</td>\n",
       "      <td></td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td></td>\n",
       "      <td>Bengali</td>\n",
       "      <td></td>\n",
       "      <td>233.7</td>\n",
       "      <td></td>\n",
       "      <td>4.000%</td>\n",
       "      <td></td>\n",
       "      <td>Indo-European</td>\n",
       "      <td></td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td>Portuguese</td>\n",
       "      <td></td>\n",
       "      <td>232.4</td>\n",
       "      <td></td>\n",
       "      <td>2.870%</td>\n",
       "      <td></td>\n",
       "      <td>Indo-European</td>\n",
       "      <td></td>\n",
       "      <td>Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td></td>\n",
       "      <td>Russian</td>\n",
       "      <td></td>\n",
       "      <td>154.0</td>\n",
       "      <td></td>\n",
       "      <td>2.000%</td>\n",
       "      <td></td>\n",
       "      <td>Indo-European</td>\n",
       "      <td></td>\n",
       "      <td>Balto-Slavic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td></td>\n",
       "      <td>Japanese</td>\n",
       "      <td></td>\n",
       "      <td>125.3</td>\n",
       "      <td></td>\n",
       "      <td>1.662%</td>\n",
       "      <td></td>\n",
       "      <td>Japonic</td>\n",
       "      <td></td>\n",
       "      <td>Japanese</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td></td>\n",
       "      <td>Western Punjabi[12]</td>\n",
       "      <td></td>\n",
       "      <td>92.7</td>\n",
       "      <td></td>\n",
       "      <td>1.204%</td>\n",
       "      <td></td>\n",
       "      <td>Indo-European</td>\n",
       "      <td></td>\n",
       "      <td>Indo-Aryan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td></td>\n",
       "      <td>Yue Chinese</td>\n",
       "      <td></td>\n",
       "      <td>85.2</td>\n",
       "      <td></td>\n",
       "      <td>0.949%</td>\n",
       "      <td></td>\n",
       "      <td>Sino-Tibetan</td>\n",
       "      <td></td>\n",
       "      <td>Sinitic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td></td>\n",
       "      <td>Vietnamese</td>\n",
       "      <td></td>\n",
       "      <td>84.6</td>\n",
       "      <td></td>\n",
       "      <td>0.987%</td>\n",
       "      <td></td>\n",
       "      <td>Austroasiatic</td>\n",
       "      <td></td>\n",
       "      <td>Vietic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                               Language   Native Speakers(millions)    \\\n",
       "0     1                       Mandarin Chinese                       929.0     \n",
       "1     2                                Spanish                       474.7     \n",
       "2     3                                English                       372.9     \n",
       "3     4    Hindi (Sanskritised Hindustani)[11]                       343.9     \n",
       "4     5                                Bengali                       233.7     \n",
       "5     6                             Portuguese                       232.4     \n",
       "6     7                                Russian                       154.0     \n",
       "7     8                               Japanese                       125.3     \n",
       "8     9                    Western Punjabi[12]                        92.7     \n",
       "9    10                            Yue Chinese                        85.2     \n",
       "10   11                             Vietnamese                        84.6     \n",
       "\n",
       "   Percentageof world pop.(March 2019)[10]   Language family          Branch  \n",
       "0                                  11.922%      Sino-Tibetan         Sinitic  \n",
       "1                                   5.994%     Indo-European         Romance  \n",
       "2                                   4.922%     Indo-European        Germanic  \n",
       "3                                   4.429%     Indo-European      Indo-Aryan  \n",
       "4                                   4.000%     Indo-European      Indo-Aryan  \n",
       "5                                   2.870%     Indo-European         Romance  \n",
       "6                                   2.000%     Indo-European    Balto-Slavic  \n",
       "7                                   1.662%           Japonic        Japanese  \n",
       "8                                   1.204%     Indo-European      Indo-Aryan  \n",
       "9                                   0.949%      Sino-Tibetan         Sinitic  \n",
       "10                                  0.987%     Austroasiatic          Vietic  "
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colnames = wiki_lang_rows[0]\n",
    "data = wiki_lang_rows[1:]\n",
    "\n",
    "df = pd.DataFrame(data[:11], columns=colnames)\n",
    "df.head(11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BONUS QUESTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scrape a certain number of tweets of a given Twitter account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "# You will need to add the account credentials to this url\n",
    "url = 'https://twitter.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMDB's Top 250 data (movie name, Initial release, director name and stars) as a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise \n",
    "url = 'https://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Movie name, year and a brief summary of the top 10 random movies (IMDB) as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the url you will scrape in this exercise\n",
    "url = 'http://www.imdb.com/chart/top'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find the live weather report (temperature, wind speed, description and weather) of a given city."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://openweathermap.org/current\n",
    "city = city=input('Enter the city:')\n",
    "url = 'http://api.openweathermap.org/data/2.5/weather?'+'q='+city+'&APPID=b35975e18dc93725acb092f7272cc6b8&units=metric'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Book name,price and stock availability as a pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the url you will scrape in this exercise. \n",
    "# It is a fictional bookstore created to be scraped. \n",
    "url = 'http://books.toscrape.com/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
